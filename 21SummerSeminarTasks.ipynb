{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21SummerSeminarTasks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNnZtBIGC1m4HHRCWv/Dsq7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oakeshott/21SS_CSPTP-based_ILP/blob/master/21SummerSeminarTasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Dlu7SQWNVDE"
      },
      "source": [
        "# 5G通信基盤を支えるネットワーク仮想化技術によるネットワークの最適設計\n",
        "\n",
        "## 目的\n",
        "\n",
        "[前回の演習](https://colab.research.google.com/drive/1ab9VKYQtsQ7VMGVRuzrq6lgtcfzo6zsK?usp=sharing)より，SPTPとサービスチェイニングの関連性について理解しました．\n",
        "この演習では，スケーラビリティの観点からSPTPに基づくサービスチェイニングの複雑性を理解することを目的としています．\n",
        "\n",
        "## 課題\n",
        "\n",
        "スケーラビリティの観点から，2つの課題に取り組んでもらう予定です．\n",
        "1. 物理ノード数に対する処理性能\n",
        "2. サービスチェイン要求数に対する処理性能\n",
        "\n",
        "なお，実験を行いやすくするために`solve()`関数を用意しました．\n",
        "これは前回作成したSPTPに基づくサービスチェイニングを行うILPを解く関数です．\n",
        "  - 入力: データセットが存在するディレクトリのパス\n",
        "  - 出力: 状態(status)，最適値(objective value), 実行時間(execution time)\n",
        "\n",
        "例えば，以下のようなプログラムを実行すると，次のような出力が得られます．\n",
        "```python\n",
        "path = \"/content/21SS_CSPTP-based_ILP/dataset/nsfnetbw\"\n",
        "status, objective_value, execution_time = solve(path)\n",
        "print(status, objective_value, execution_time)\n",
        "Optimal 121.44999999999996 0.06714981600089232\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLrFIe9lBBSs",
        "outputId": "f2e64f97-beb0-4c0d-bd37-38e948611e29"
      },
      "source": [
        "!pip install pulp networkx matplotlib pandas"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pulp in /usr/local/lib/python3.7/dist-packages (2.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: amply>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from pulp) (0.1.4)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from amply>=0.1.2->pulp) (2.4.7)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.7/dist-packages (from amply>=0.1.2->pulp) (0.17.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx) (4.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoKAEhYqBPxR",
        "outputId": "11bb048f-1058-4f6b-a90f-4aed98a5bbbc"
      },
      "source": [
        "!rm -rf /content/21SS_CSPTP-based_ILP/\n",
        "!git clone https://github.com/oakeshott/21SS_CSPTP-based_ILP"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '21SS_CSPTP-based_ILP'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/166)\u001b[K\rremote: Counting objects:   1% (2/166)\u001b[K\rremote: Counting objects:   2% (4/166)\u001b[K\rremote: Counting objects:   3% (5/166)\u001b[K\rremote: Counting objects:   4% (7/166)\u001b[K\rremote: Counting objects:   5% (9/166)\u001b[K\rremote: Counting objects:   6% (10/166)\u001b[K\rremote: Counting objects:   7% (12/166)\u001b[K\rremote: Counting objects:   8% (14/166)\u001b[K\rremote: Counting objects:   9% (15/166)\u001b[K\rremote: Counting objects:  10% (17/166)\u001b[K\rremote: Counting objects:  11% (19/166)\u001b[K\rremote: Counting objects:  12% (20/166)\u001b[K\rremote: Counting objects:  13% (22/166)\u001b[K\rremote: Counting objects:  14% (24/166)\u001b[K\rremote: Counting objects:  15% (25/166)\u001b[K\rremote: Counting objects:  16% (27/166)\u001b[K\rremote: Counting objects:  17% (29/166)\u001b[K\rremote: Counting objects:  18% (30/166)\u001b[K\rremote: Counting objects:  19% (32/166)\u001b[K\rremote: Counting objects:  20% (34/166)\u001b[K\rremote: Counting objects:  21% (35/166)\u001b[K\rremote: Counting objects:  22% (37/166)\u001b[K\rremote: Counting objects:  23% (39/166)\u001b[K\rremote: Counting objects:  24% (40/166)\u001b[K\rremote: Counting objects:  25% (42/166)\u001b[K\rremote: Counting objects:  26% (44/166)\u001b[K\rremote: Counting objects:  27% (45/166)\u001b[K\rremote: Counting objects:  28% (47/166)\u001b[K\rremote: Counting objects:  29% (49/166)\u001b[K\rremote: Counting objects:  30% (50/166)\u001b[K\rremote: Counting objects:  31% (52/166)\u001b[K\rremote: Counting objects:  32% (54/166)\u001b[K\rremote: Counting objects:  33% (55/166)\u001b[K\rremote: Counting objects:  34% (57/166)\u001b[K\rremote: Counting objects:  35% (59/166)\u001b[K\rremote: Counting objects:  36% (60/166)\u001b[K\rremote: Counting objects:  37% (62/166)\u001b[K\rremote: Counting objects:  38% (64/166)\u001b[K\rremote: Counting objects:  39% (65/166)\u001b[K\rremote: Counting objects:  40% (67/166)\u001b[K\rremote: Counting objects:  41% (69/166)\u001b[K\rremote: Counting objects:  42% (70/166)\u001b[K\rremote: Counting objects:  43% (72/166)\u001b[K\rremote: Counting objects:  44% (74/166)\u001b[K\rremote: Counting objects:  45% (75/166)\u001b[K\rremote: Counting objects:  46% (77/166)\u001b[K\rremote: Counting objects:  47% (79/166)\u001b[K\rremote: Counting objects:  48% (80/166)\u001b[K\rremote: Counting objects:  49% (82/166)\u001b[K\rremote: Counting objects:  50% (83/166)\u001b[K\rremote: Counting objects:  51% (85/166)\u001b[K\rremote: Counting objects:  52% (87/166)\u001b[K\rremote: Counting objects:  53% (88/166)\u001b[K\rremote: Counting objects:  54% (90/166)\u001b[K\rremote: Counting objects:  55% (92/166)\u001b[K\rremote: Counting objects:  56% (93/166)\u001b[K\rremote: Counting objects:  57% (95/166)\u001b[K\rremote: Counting objects:  58% (97/166)\u001b[K\rremote: Counting objects:  59% (98/166)\u001b[K\rremote: Counting objects:  60% (100/166)\u001b[K\rremote: Counting objects:  61% (102/166)\u001b[K\rremote: Counting objects:  62% (103/166)\u001b[K\rremote: Counting objects:  63% (105/166)\u001b[K\rremote: Counting objects:  64% (107/166)\u001b[K\rremote: Counting objects:  65% (108/166)\u001b[K\rremote: Counting objects:  66% (110/166)\u001b[K\rremote: Counting objects:  67% (112/166)\u001b[K\rremote: Counting objects:  68% (113/166)\u001b[K\rremote: Counting objects:  69% (115/166)\u001b[K\rremote: Counting objects:  70% (117/166)\u001b[K\rremote: Counting objects:  71% (118/166)\u001b[K\rremote: Counting objects:  72% (120/166)\u001b[K\rremote: Counting objects:  73% (122/166)\u001b[K\rremote: Counting objects:  74% (123/166)\u001b[K\rremote: Counting objects:  75% (125/166)\u001b[K\rremote: Counting objects:  76% (127/166)\u001b[K\rremote: Counting objects:  77% (128/166)\u001b[K\rremote: Counting objects:  78% (130/166)\u001b[K\rremote: Counting objects:  79% (132/166)\u001b[K\rremote: Counting objects:  80% (133/166)\u001b[K\rremote: Counting objects:  81% (135/166)\u001b[K\rremote: Counting objects:  82% (137/166)\u001b[K\rremote: Counting objects:  83% (138/166)\u001b[K\rremote: Counting objects:  84% (140/166)\u001b[K\rremote: Counting objects:  85% (142/166)\u001b[K\rremote: Counting objects:  86% (143/166)\u001b[K\rremote: Counting objects:  87% (145/166)\u001b[K\rremote: Counting objects:  88% (147/166)\u001b[K\rremote: Counting objects:  89% (148/166)\u001b[K\rremote: Counting objects:  90% (150/166)\u001b[K\rremote: Counting objects:  91% (152/166)\u001b[K\rremote: Counting objects:  92% (153/166)\u001b[K\rremote: Counting objects:  93% (155/166)\u001b[K\rremote: Counting objects:  94% (157/166)\u001b[K\rremote: Counting objects:  95% (158/166)\u001b[K\rremote: Counting objects:  96% (160/166)\u001b[K\rremote: Counting objects:  97% (162/166)\u001b[K\rremote: Counting objects:  98% (163/166)\u001b[K\rremote: Counting objects:  99% (165/166)\u001b[K\rremote: Counting objects: 100% (166/166)\u001b[K\rremote: Counting objects: 100% (166/166), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 166 (delta 112), reused 157 (delta 106), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (166/166), 10.00 MiB | 20.82 MiB/s, done.\n",
            "Resolving deltas: 100% (112/112), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egh6lkkRBQH-"
      },
      "source": [
        "import pulp\n",
        "import networkx as nx\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import time\n",
        "import pandas as pd"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQl6ScwINntq"
      },
      "source": [
        "def solve(path=\"/content/21SS_CSPTP-based_ILP/dataset/nsfnetbw\"):\n",
        "    filename = os.path.join(path, \"network.gml\")\n",
        "    physical_network = nx.read_gml(filename, label=\"id\")\n",
        "    physical_node_size = len(physical_network.nodes())\n",
        "\n",
        "    filename = os.path.join(path, \"service_chain_requirements.json\")\n",
        "    with open(filename) as f:\n",
        "        connections = json.load(f)\n",
        "    for connection in connections:\n",
        "        connection['required_processing_func'] = {int(k): v for k, v in connection['required_processing_func'].items()}\n",
        "\n",
        "    filename = os.path.join(path, \"function_placement.json\")\n",
        "    with open(filename) as f:\n",
        "      function_placement = json.load(f)\n",
        "    placement = function_placement[\"placement\"]\n",
        "    F = set(function_placement['functions'])\n",
        "\n",
        "    imaginary_links = pd.DataFrame.from_dict(placement)\n",
        "    imaginary_nodes = {f: f+physical_node_size for f in F}\n",
        "\n",
        "    G = physical_network.copy()\n",
        "    for func, node in imaginary_nodes.items():\n",
        "        G.add_node(node, lng=-(func+1)*8 - 70, lat=60, delay=0)\n",
        "    imaginary_links.apply(lambda x: G.add_edge(x.physical_node, imaginary_nodes[x.function], delay=0), axis=1)\n",
        "    imaginary_links.apply(lambda x: G.add_edge(imaginary_nodes[x.function], x.physical_node, delay=x.delay * 1e-3), axis=1) # d_{i,j}^{func}\n",
        "\n",
        "    a = []\n",
        "    b = []\n",
        "    for c in connections:\n",
        "        R_c = c['request']\n",
        "        K_c = len(R_c)\n",
        "        o_c = c['origin']\n",
        "        d_c = c['destination']\n",
        "        a_ck = []\n",
        "        b_ck = []\n",
        "        for k in range(K_c+1):\n",
        "            if k == 0:\n",
        "                a_ck.append(o_c)\n",
        "            if k == K_c:\n",
        "                b_ck.append(d_c)\n",
        "            else:\n",
        "                a_ck.append(imaginary_nodes[R_c[k]])\n",
        "                b_ck.append(imaginary_nodes[R_c[k]])\n",
        "        a.append(a_ck)\n",
        "        b.append(b_ck)\n",
        "\n",
        "    # formualte ILP\n",
        "    m = pulp.LpProblem(\"SPTP-based-ILP\", pulp.LpMinimize)\n",
        "\n",
        "    x = {}\n",
        "    for c, connection in enumerate(connections):\n",
        "        K_c = len(connection['request'])\n",
        "        for k in range(K_c+1):\n",
        "            for i, j in G.edges():\n",
        "                x[i,j,c,k] = pulp.LpVariable(\"x_{:},{:},{:},{:}\".format(i, j, c, k), 0, 1, pulp.LpBinary)\n",
        "\n",
        "    m += pulp.lpSum(G[i][j][\"delay\"] * pulp.lpSum(x[i,j,c,k]           for c in range(len(connections)) for k in range(len(connections[c]['request'])+1) ) for i, j in physical_network.edges()) \\\n",
        "            + pulp.lpSum(G.nodes()[v][\"delay\"] * pulp.lpSum(x[v,j,c,k] for c in range(len(connections)) for k in range(len(connections[c]['request'])+1) ) for v, j in physical_network.edges()) \\\n",
        "            + pulp.lpSum(G[v_f][v][\"delay\"] * pulp.lpSum(x[v_f,v,c,k]  for c in range(len(connections)) for k in range(len(connections[c]['request'])+1) ) for v_f, v in G.edges() if v_f in imaginary_nodes.values()), \"Objective function\"\n",
        "\n",
        "    for c, connection in enumerate(connections):\n",
        "        K_c = len(connection['request'])\n",
        "        for k in range(K_c + 1):\n",
        "            for i in G.nodes():\n",
        "                if i == a[c][k]:\n",
        "                    m += pulp.lpSum(x[i, j, c, k] for j in G.neighbors(i)) == 1, f\"flow_constraint_c{c}_k{k}_i{i}\"\n",
        "                elif i == b[c][k]:\n",
        "                    m += pulp.lpSum(x[j, i, c, k] for j in G.neighbors(i) ) == 1, f\"flow_constraint_c{c}_k{k}_i{i}\"\n",
        "                else:\n",
        "                    m += pulp.lpSum(x[i, j, c, k] for j in G.neighbors(i)) == pulp.lpSum(x[j, i, c, k] for j in G.neighbors(i)), f\"flow_constraint_c{c}_k{k}_i{i}\"\n",
        "\n",
        "    for c, connection in enumerate(connections):\n",
        "        K_c = len(connection['request'])\n",
        "        for k in range(K_c):\n",
        "            v_f_ck = b[c][k]\n",
        "            for i in G.neighbors(v_f_ck):\n",
        "                m += x[i, v_f_ck, c, k] == x[v_f_ck, i, c, k+1], \"connectivity_of_subpath_constraint_i{:}j{:}c{:}k{:}\".format(i, v_f_ck, c, k)\n",
        "\n",
        "    for c, connection in enumerate(connections):\n",
        "        K_c = len(connection['request'])\n",
        "        for k in range(K_c+1):\n",
        "            for i, v_f in G.edges():\n",
        "                if v_f in imaginary_nodes.values() and not v_f is b[c][k]:\n",
        "                    m += x[i, v_f, c, k] == 0, \"infeasible_link_i{:}j{:}k{:}c{:}\".format(i, v_f, k, c)\n",
        "\n",
        "    for i, j in physical_network.edges():\n",
        "        m += pulp.lpSum(connection['required_bandwidth'] * pulp.lpSum(x[i, j, c, k] for k in range(len(connection['request'])+1)) for c, connection in enumerate(connections)) <= physical_network[i][j][\"bandwidth\"], \"physical_link_capacity_i{:}j{:}\".format(i, j)\n",
        "\n",
        "    for v in physical_network.nodes():\n",
        "        m += pulp.lpSum(connection[\"required_processing_node\"] * pulp.lpSum(x[v,j,c,k] for j in physical_network.neighbors(v) for k in range(len(connection['request'])+1)) + \\\n",
        "                pulp.lpSum(connection[\"required_processing_func\"][v_f-physical_node_size] * pulp.lpSum(x[v_f,v,c,k] for k in range(len(connection['request'])+1)) for v_f in G.neighbors(v) if v_f in imaginary_nodes.values() and v_f-physical_node_size in connection['request']) for c, connection in enumerate(connections)) \\\n",
        "                <= physical_network.nodes()[v][\"capacity\"], \"processing_capacity_constraint_v{:}\".format(v)\n",
        "\n",
        "    for c, connection in enumerate(connections):\n",
        "        K_c = len(connection['request'])\n",
        "        o = connection['origin']\n",
        "        d = connection['destination']\n",
        "        m += pulp.lpSum(x[i,o,c,0] for i in G.neighbors(o)) == 0, \"constraint_7_w{:}\".format(c)\n",
        "        m += pulp.lpSum(x[d,i,c,len(connection['request'])] for i in G.neighbors(d)) == 0, \"constraint_8_w{:}\".format(c)\n",
        "\n",
        "    start = time.perf_counter()\n",
        "    status = m.solve()\n",
        "    end = time.perf_counter()\n",
        "    elapsed = end - start\n",
        "\n",
        "    return pulp.LpStatus[status], pulp.value(m.objective), elapsed\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTTCXw1vNt7q",
        "outputId": "b394c2a7-7d24-4994-e5aa-e47106024227"
      },
      "source": [
        "path = \"/content/21SS_CSPTP-based_ILP/dataset/nsfnetbw\"\n",
        "status, objective_value, execution_time = solve(path)\n",
        "print(status, objective_value, execution_time)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal 121.44999999999996 0.06714981600089232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEmmgrKJeYT4"
      },
      "source": [
        "# ノード数に対する処理性能の変化\n",
        "まず，SPTPに基づくILPのスケーラビリティを確認するために，ノード数に対する処理性能を調査してもらいます．  \n",
        "ノード数100から1000までのファイル群を入力として，ノード数の増加に伴い，実行時間がどのように推移するのかを確認してください．  \n",
        "入力ファイルに関しては，下記のディレクトリに存在します．  \n",
        "`/content/21SS_CSPTP-based_ILP/dataset/nrof_nodes{n}`  \n",
        "ここで`{n}`はノード数を表しています．\n",
        "\n",
        "なお，結果に関しては，図などを利用して表示してください．\n",
        "その際に，[matplotlib](https://matplotlib.org/)や[pandas](https://pandas.pydata.org/docs/)を利用してもらうことになるかと思います．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8y69iP9OHd7"
      },
      "source": [
        "!ls /content/21SS_CSPTP-based_ILP/dataset/nrof_nodes*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx82YTISi8UM"
      },
      "source": [
        "# サービスチェイン要求数に対する処理性能の変化\n",
        "まず，SPTPに基づくILPのスケーラビリティを確認するために，サービスチェイン要求数に対する処理性能を調査してもらいます．  \n",
        "ノード数100から1000までのファイル群を入力として，サービスチェイン要求数の増加に伴い，実行時間がどのように推移するのかを確認してください．  \n",
        "入力ファイルに関しては，下記のディレクトリに存在します．  \n",
        "`/content/21SS_CSPTP-based_ILP/dataset/nrof_connections{c}`  \n",
        "ここで`{c}`はサービスチェイン要求数を表しています．\n",
        "\n",
        "なお，結果に関しては同様に，図などを利用して表示してください．\n",
        "その際に，[matplotlib](https://matplotlib.org/)や[pandas](https://pandas.pydata.org/docs/)を利用してもらうことになるかと思います．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlnPowPEON9M"
      },
      "source": [
        "!ls /content/21SS_CSPTP-based_ILP/dataset/nrof_connections*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXu1YlNjjjhH"
      },
      "source": [
        "# 課題3: 運用面を考慮したサービスチェイニング (時間があれば)\n",
        "\n",
        "課題1，2より，スケーラビリティの観点から，SPTPに基づくサービスチェイニングのILPは十分な計算量が必要となることを確認しました．\n",
        "一般に解の最適性と計算時間にはトレードオフ関係にあることがいえます．\n",
        "計算時間の増加はユーザに迅速なサービス提供ができなくなり，QoSの低下に繋がります．\n",
        "これは運用面においてもシステムが機能しなくなり，管理コストが増大することが懸念されます．\n",
        "ネットワークに接続するデバイス数の増加や多様化するネットワークサービスに伴い，ネットワークは複雑化する中で迅速かつ最適なサービスチェイニングを実現する方法を検討してください．（アイデアベースのものでも構いません．）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Utg3tciNXQGC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}